
## Zero-Forcing Beamformer Problem 

What wieght vector can null out angles of arrival `theta1,theta2,..theta_k`. and protects the angle of arrival `theta_0`

![img1](lecture_1_17_2018_img/lec01.png "img1")

Lets say that for some arbitrary angle of arrival , `theta_i ; i=1,2,..k` we can rewrite the angle of arrival as such:

![img2](lecture_1_17_2018_img/lec02.png "img2")

To place "nulls" at `theta1,theta2,..theta_k` you need to find a vector W , such that :

![img](lecture_1_17_2018_img/lec03.png "img")

This is caled the deterministic zero-forcing beamformer. Lets create a matrix from the weights and array reponse vectors to create `A` . And a vector of all the angles of arrival, `e` that would null out the theta components that we are seeking to null out.

![img](lecture_1_17_2018_img/lec04.png "img")

> Q. What is the maximum number of nulls that you can you place? K+1=M => K=M-1, one less than the amount of elements you have in the element array.

Notice that this is a full rank matrix, because the A is a matrix of M by (K+1).
If k+1=M , then we can rewrite the arrays and matrix as :

![img](lecture_1_17_2018_img/lec05.png "img")

And if we continue and assume that M>k+1 then we can rewrite it as the following. Notice that we find the Moore-Penrose psuedo inverse of `A`.

![img](lecture_1_17_2018_img/lec06.png "img")

# Statistical Suppression

Lets consider additive noise added to our input signal.

![img](lecture_1_17_2018_img/lec07.png "img")

Remember what the input signal is for our linear array. The arriving signal on some carrier frequeny times the ith element component spaced by the distance.

![img](lecture_1_17_2018_img/lec12.png "img")


We can use a white gaussian function to represent our noise signals.Lets also assume that the noise acrros each of the inputs is not correlated. (we cannot always assume this when the antennas are very close to each other). When we say white gaussian process we mean that the expected value mean is equal to 0. and if you calculate the autocorrelation function wich is the expected value of hte process at time t times the conjugate of the process at some time t, minus tau  can be denoted by some constant`sigma^2` times some `delta(tau)`, where `i=1,2,...,M` where M is number of elements. The `sigma^2` is what we call the power specral density.

![img](lecture_1_17_2018_img/lec08.png "img")

What happens across antenna elements? In other words try to calculate the expected value of `n_i` at some time t, times the conjugate of `n_j` at some time t is equal to 0. We can assume this for now but it can be different in other problems.

 ![img](lecture_1_17_2018_img/lec13.png "img")


## Signal To Noise Ratio

Once a signal has noise there is no real way to get rid of it. But we can figure out the ratio of signal over noise and then try to maximize the weight vector so that the signal to noise ratio is at its maximum.

## SNR Optimization Problem

Find weight vector that maximizes the output SNR :

We are looking for the weight vector `w` that is the argument that maximizes over all accesible `w` in the complex vector space to M, as a ratio defined as the signal power of the output over the noise power. We define the power of the signal power as the expected value of the weight-hermitian vector times the input vector squared. Similarly the noise power at the output is the expected value of the weight-heritian vector times the noise vector squared.

We define the `n(t)` as the M-dimensional random noise process for each element.

![img](lecture_1_17_2018_img/lec09.png "img")

### Solution

The input signal is whats coming in `m(t)` ont he carrier `fc` at some angle of arraival defined as the response vector `S_theta`. Then the average square magnitude of w-hermitan becomes the expected mangitude of `|m(t) * w^H * S_theta|^2`. This can the be expanded to become the expectation of the random part `m(t)` times the constants of `|w^H*S_theta|^2`. We can call the expectation of the arrving signal `rho`.

![img](lecture_1_17_2018_img/lec14.png "img")

Finally, we can rewrite the numerator (signal) part of the SNR in terms of `rho`. by equating the output squared expected to `rho*|w^H*S_theta|^2`.

![img](lecture_1_17_2018_img/lec15.png "img")

Now lets look at the denominator , wich is the expected value of the noise output, `E{|w^H*n(t)|^2}`. We must remember that the squared magnitude of a complex number is the number times the conjugate.

> `|z|^2 = z . z* where z is a complex number `

We can rewrite this denominator as and expanded form of the complex multiplication of w and n(t) and treat is as a single complex value squared and applying the rule. We then convert the conjugate term to its non-conjugate form. 

![img](lecture_1_17_2018_img/lec16.png "img")

Lets identify what is random and what is not. The non random weight vector can be pulled out of the expectation and get the expectation with the noise signal multiplied by its hermitian. This is called the auto-correlation matrix. 

![img](lecture_1_17_2018_img/lec17.png "img")

Since we assumed that the PSD at the noise process at its antenna element is the same and equal to `sigma^2` and that the noise process across antenna elements are independent, auto-correlated. This matrix becomes `sigma^2` times an identity matrix with size M. 

We can rewrite the result as `sigma^2 * w^H*w` . The `w^H*w` is the norm squared of the vector. Since w^H is just the conjugated and transposed matrix we can think of the w vector multiplying by itself and only crossing at one point. So since the two are multuplying at the sam value it becomes squared.

![img](lecture_1_17_2018_img/lec18.png "img")

We can now conclude the value of hte snr by the numerator and denominator we have defined above.The SNR at the output of a system at some angle of arrival theta.

![img](lecture_1_17_2018_img/lec10.png "img")

### Maximizing the SNR

What weight vector can maximize the SNR? This is a criterion that we want in this particular case. There could be no solution to this criterion, but if there is then we succeed in creating a maximum SNR ratio and possible using this to suppress noise and improve signal.

![img](lecture_1_17_2018_img/lec19.png "img")

Lets observer Schwarz's  inequality, that states that the magnitude squared of an expression like what we see in our numerator is always less than or equal to the norm of the first vector squared times the norm of your second vector squared.

![img](lecture_1_17_2018_img/lec20.png "img")

This theorem says that equality can be met if and only if the first vector is a scaled vector of the other. So in our case the weight vector must be a scaled version of the array response vector in order ot be maximized.

![img](lecture_1_17_2018_img/lec21.png "img")

Lets return to the problem and see if this inequality could help us determine the maximum SNR. Lets pick the scenario when the weight vector is equal to the array response vector. This allows us to replace the `w^H` in the numerator with `S_theta^H` , note that `S_theta` would equal to 1. We can change our scaled value to 1/M so that instead of one in the numerator we get M. 

![img](lecture_1_17_2018_img/lec22.png "img")

### Conclusion
We can now conlcude the following

1. The weights vector optimized for the max SNR is called the matched filter beamformer or conventional beam former.![img](lecture_1_17_2018_img/lec23.png "img")

2. The maximum output SNR that is possible when using the matched filter beamformer would be `rho/sigma^2` times some scaled version of `S_theta` (consider scaled by 1 for example) used in the numerator and denominator of the `|S_theta^H*S_theta|^2/||S_theta||^2` . The numerator now becomes `M^2 / M` wich then becomes equal to `M*(rho/sigma^2)`.
[img](lecture_1_17_2018_img/lec24.png "img")

This now shows us that we can pick up any signal with an sufficient number of elements in our antenna array.

 3. If the weights vector is equal to the array response vector then a phased array is sufficient to achieve maximum SNR when you process one signal in WGN (white gaussian noise), independent from antenna to antenna.

 
